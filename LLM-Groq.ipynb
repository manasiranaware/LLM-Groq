{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01bb83c1-6a52-4e95-a6b9-fe57cebf41c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "chromadb 0.5.15 requires overrides>=7.3.1, which is not installed.\n",
      "chromadb 0.5.15 requires tokenizers>=0.13.2, which is not installed.\n",
      "chromadb 0.5.15 requires tqdm>=4.65.0, which is not installed.\n",
      "huggingface-hub 0.25.1 requires filelock, which is not installed.\n",
      "huggingface-hub 0.25.1 requires tqdm>=4.42.1, which is not installed.\n",
      "kubernetes 31.0.0 requires websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0, which is not installed.\n",
      "langchain 0.3.1 requires aiohttp<4.0.0,>=3.8.3, which is not installed.\n",
      "langchain 0.3.1 requires SQLAlchemy<3,>=1.4, which is not installed.\n",
      "langchain-community 0.3.1 requires aiohttp<4.0.0,>=3.8.3, which is not installed.\n",
      "langchain-community 0.3.1 requires SQLAlchemy<3,>=1.4, which is not installed.\n",
      "uvicorn 0.31.1 requires click>=7.0, which is not installed.\n"
     ]
    }
   ],
   "source": [
    "#pip install -qU langchain-groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "babe7a05-78dc-457f-9153-cdf37e17031d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.1-70b-versatile\",\n",
    "    temperature=0.5,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    api_key=\"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\"\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7859fa7c-b4ac-49be-b442-e10d6baa8a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As a medicine practitioner, I'd like to help you alleviate your headache. Before I suggest any medications, I'd like to know a bit more about your headache. Can you please tell me:\\n\\n1. How long have you been experiencing this headache?\\n2. How severe is the headache (mild, moderate, or severe)?\\n3. Is the headache constant or does it come and go?\\n4. Do you have any other symptoms, such as fever, nausea, or sensitivity to light?\\n5. Have you taken any medications or tried any remedies already?\\n\\nAssuming you're experiencing a typical tension headache, here are some common over-the-counter (OTC) medications that may help:\\n\\n1. **Acetaminophen (Tylenol)**: This is a pain reliever that can help with mild to moderate headaches.\\n2. **Ibuprofen (Advil, Motrin)**: This is a non-steroidal anti-inflammatory drug (NSAID) that can help with pain and inflammation.\\n3. **Aspirin**: This is another NSAID that can help with pain and inflammation.\\n4. **Excedrin**: This is a combination medication that contains acetaminophen, aspirin, and caffeine, which can help with tension headaches.\\n\\nIf your headache is more severe or persistent, I may recommend prescription medications such as:\\n\\n1. **Triptans (e.g., Imitrex, Maxalt)**: These medications are specifically designed to treat migraines and can help with severe headaches.\\n2. **Ergotamines (e.g., Ergomar)**: These medications can help with migraines and cluster headaches.\\n\\nPlease keep in mind that it's essential to consult with a healthcare professional before taking any medication, especially if you have a pre-existing medical condition or take other medications regularly.\\n\\nIn addition to medications, here are some non-pharmacological remedies that may help:\\n\\n1. **Stay hydrated**: Drink plenty of water to help your body replenish fluids.\\n2. **Rest**: Lie down in a quiet, dark room to help your body relax.\\n3. **Apply heat or cold**: Use a warm or cold compress to help relax your muscles.\\n4. **Practice relaxation techniques**: Try deep breathing, meditation, or yoga to help reduce stress and tension.\\n\\nRemember, if your headache is severe, persistent, or accompanied by other concerning symptoms (such as fever, confusion, or weakness), please seek medical attention immediately.\\n\\nHow do you feel about trying some of these suggestions?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 509, 'prompt_tokens': 59, 'total_tokens': 568, 'completion_time': 2.074866815, 'prompt_time': 0.019794805, 'queue_time': 0.149934598, 'total_time': 2.09466162}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_9260b4bb2e', 'finish_reason': 'stop', 'logprobs': None}, id='run-70995497-82c6-4e17-a94f-924dcf907d5c-0', usage_metadata={'input_tokens': 59, 'output_tokens': 509, 'total_tokens': 568})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a famous mediciane practitioner.help to solve medical issues.\",\n",
    "    ),\n",
    "    (\"human\", \"I have head ache.suggest me some mediciences\"),\n",
    "]\n",
    "ai_msg = llm.invoke(messages)\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81297f48-1b81-4f54-b67b-53af7a20dd75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As a medicine practitioner, I'd like to help you alleviate your headache. Before I suggest any medications, I'd like to know a bit more about your headache. Can you please tell me:\n",
      "\n",
      "1. How long have you been experiencing this headache?\n",
      "2. How severe is the headache (mild, moderate, or severe)?\n",
      "3. Is the headache constant or does it come and go?\n",
      "4. Do you have any other symptoms, such as fever, nausea, or sensitivity to light?\n",
      "5. Have you taken any medications or tried any remedies already?\n",
      "\n",
      "Assuming you're experiencing a typical tension headache, here are some common over-the-counter (OTC) medications that may help:\n",
      "\n",
      "1. **Acetaminophen (Tylenol)**: This is a pain reliever that can help with mild to moderate headaches.\n",
      "2. **Ibuprofen (Advil, Motrin)**: This is a non-steroidal anti-inflammatory drug (NSAID) that can help with pain and inflammation.\n",
      "3. **Aspirin**: This is another NSAID that can help with pain and inflammation.\n",
      "4. **Excedrin**: This is a combination medication that contains acetaminophen, aspirin, and caffeine, which can help with tension headaches.\n",
      "\n",
      "If your headache is more severe or persistent, I may recommend prescription medications such as:\n",
      "\n",
      "1. **Triptans (e.g., Imitrex, Maxalt)**: These medications are specifically designed to treat migraines and can help with severe headaches.\n",
      "2. **Ergotamines (e.g., Ergomar)**: These medications can help with migraines and cluster headaches.\n",
      "\n",
      "Please keep in mind that it's essential to consult with a healthcare professional before taking any medication, especially if you have a pre-existing medical condition or take other medications regularly.\n",
      "\n",
      "In addition to medications, here are some non-pharmacological remedies that may help:\n",
      "\n",
      "1. **Stay hydrated**: Drink plenty of water to help your body replenish fluids.\n",
      "2. **Rest**: Lie down in a quiet, dark room to help your body relax.\n",
      "3. **Apply heat or cold**: Use a warm or cold compress to help relax your muscles.\n",
      "4. **Practice relaxation techniques**: Try deep breathing, meditation, or yoga to help reduce stress and tension.\n",
      "\n",
      "Remember, if your headache is severe, persistent, or accompanied by other concerning symptoms (such as fever, confusion, or weakness), please seek medical attention immediately.\n",
      "\n",
      "How do you feel about trying some of these suggestions?\n"
     ]
    }
   ],
   "source": [
    "print(ai_msg.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2484587-1be2-4388-8661-0cf8582612b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chromadb in c:\\users\\rsc\\appdata\\roaming\\python\\python311\\site-packages (0.5.15)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torch 2.4.1 requires jinja2, which is not installed.\n",
      "torch 2.4.1 requires networkx, which is not installed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: build>=1.0.3 in c:\\users\\rsc\\appdata\\roaming\\python\\python311\\site-packages (from chromadb) (1.2.2.post1)\n",
      "Requirement already satisfied: pydantic>=1.9 in c:\\users\\rsc\\appdata\\roaming\\python\\python311\\site-packages (from chromadb) (2.9.2)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.6 in c:\\users\\rsc\\appdata\\roaming\\python\\python311\\site-packages (from chromadb) (0.7.6)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in c:\\users\\rsc\\appdata\\roaming\\python\\python311\\site-packages (from chromadb) (0.115.2)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in c:\\users\\rsc\\appdata\\roaming\\python\\python311\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.31.1)\n",
      "Requirement already satisfied: numpy>=1.22.5 in c:\\users\\rsc\\.conda\\envs\\dsml33_env1\\lib\\site-packages (from chromadb) (1.26.4)\n",
      "Requirement already satisfied: posthog>=2.4.0 in c:\\users\\rsc\\appdata\\roaming\\python\\python311\\site-packages (from chromadb) (3.7.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\rsc\\appdata\\roaming\\python\\python311\\site-packages (from chromadb) (4.12.2)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\users\\rsc\\appdata\\roaming\\python\\python311\\site-packages (from chromadb) (1.19.2)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in c:\\users\\rsc\\appdata\\roaming\\python\\python311\\site-packages (from chromadb) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in c:\\users\\rsc\\appdata\\roaming\\python\\python311\\site-packages (from chromadb) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in c:\\users\\rsc\\appdata\\roaming\\python\\python311\\site-packages (from chromadb) (0.48b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in c:\\users\\rsc\\appdata\\roaming\\python\\python311\\site-packages (from chromadb) (1.27.0)\n",
      "Collecting tokenizers>=0.13.2 (from chromadb)\n",
      "  Downloading tokenizers-0.20.1-cp311-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pypika>=0.48.9 in c:\\users\\rsc\\appdata\\roaming\\python\\python311\\site-packages (from chromadb) (0.48.9)\n",
      "Collecting tqdm>=4.65.0 (from chromadb)\n",
      "  Downloading tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting overrides>=7.3.1 (from chromadb)\n",
      "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\rsc\\appdata\\roaming\\python\\python311\\site-packages (from chromadb) (6.4.5)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\rsc\\appdata\\roaming\\python\\python311\\site-packages (from chromadb) (1.66.1)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in c:\\users\\rsc\\appdata\\roaming\\python\\python311\\site-packages (from chromadb) (4.2.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in c:\\users\\rsc\\appdata\\roaming\\python\\python311\\site-packages (from chromadb) (0.12.5)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in c:\\users\\rsc\\appdata\\roaming\\python\\python311\\site-packages (from chromadb) (31.0.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in c:\\users\\rsc\\.conda\\envs\\dsml33_env1\\lib\\site-packages (from chromadb) (8.5.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in c:\\users\\rsc\\.conda\\envs\\dsml33_env1\\lib\\site-packages (from chromadb) (6.0.2)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in c:\\users\\rsc\\appdata\\roaming\\python\\python311\\site-packages (from chromadb) (5.0.1)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\rsc\\appdata\\roaming\\python\\python311\\site-packages (from chromadb) (3.10.7)\n",
      "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\rsc\\appdata\\roaming\\python\\python311\\site-packages (from chromadb) (0.27.2)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\rsc\\appdata\\roaming\\python\\python311\\site-packages (from chromadb) (13.8.0)\n",
      "Requirement already satisfied: packaging>=19.1 in c:\\users\\rsc\\appdata\\roaming\\python\\python311\\site-packages (from build>=1.0.3->chromadb) (24.1)\n",
      "Requirement already satisfied: pyproject_hooks in c:\\users\\rsc\\appdata\\roaming\\python\\python311\\site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\rsc\\.conda\\envs\\dsml33_env1\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Requirement already satisfied: starlette<0.41.0,>=0.37.2 in c:\\users\\rsc\\appdata\\roaming\\python\\python311\\site-packages (from fastapi>=0.95.2->chromadb) (0.40.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\rsc\\.conda\\envs\\dsml33_env1\\lib\\site-packages (from httpx>=0.27.0->chromadb) (4.6.2.post1)\n",
      "Requirement already satisfied: certifi in c:\\users\\rsc\\.conda\\envs\\dsml33_env1\\lib\\site-packages (from httpx>=0.27.0->chromadb) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\rsc\\.conda\\envs\\dsml33_env1\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.0.6)\n",
      "Requirement already satisfied: idna in c:\\users\\rsc\\.conda\\envs\\dsml33_env1\\lib\\site-packages (from httpx>=0.27.0->chromadb) (3.8)\n",
      "Requirement already satisfied: sniffio in c:\\users\\rsc\\.conda\\envs\\dsml33_env1\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\rsc\\.conda\\envs\\dsml33_env1\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\rsc\\.conda\\envs\\dsml33_env1\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\rsc\\.conda\\envs\\dsml33_env1\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in c:\\users\\rsc\\appdata\\roaming\\python\\python311\\site-packages (from kubernetes>=28.1.0->chromadb) (2.35.0)\n",
      "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\rsc\\.conda\\envs\\dsml33_env1\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
      "Requirement already satisfied: requests-oauthlib in c:\\users\\rsc\\appdata\\roaming\\python\\python311\\site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in c:\\users\\rsc\\appdata\\roaming\\python\\python311\\site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in c:\\users\\rsc\\.conda\\envs\\dsml33_env1\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.2.2)\n",
      "Requirement already satisfied: durationpy>=0.7 in c:\\users\\rsc\\appdata\\roaming\\python\\python311\\site-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\rsc\\appdata\\roaming\\python\\python311\\site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\rsc\\appdata\\roaming\\python\\python311\\site-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
      "Requirement already satisfied: protobuf in c:\\users\\rsc\\appdata\\roaming\\python\\python311\\site-packages (from onnxruntime>=1.14.1->chromadb) (4.25.4)\n",
      "Collecting sympy (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in c:\\users\\rsc\\appdata\\roaming\\python\\python311\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n",
      "Collecting importlib-metadata<=8.4.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
      "  Downloading importlib_metadata-8.4.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in c:\\users\\rsc\\appdata\\roaming\\python\\python311\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.65.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.27.0 in c:\\users\\rsc\\appdata\\roaming\\python\\python311\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.27.0 in c:\\users\\rsc\\appdata\\roaming\\python\\python311\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.48b0 in c:\\users\\rsc\\appdata\\roaming\\python\\python311\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.48b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.48b0 in c:\\users\\rsc\\appdata\\roaming\\python\\python311\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.48b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.48b0 in c:\\users\\rsc\\appdata\\roaming\\python\\python311\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.48b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.48b0 in c:\\users\\rsc\\appdata\\roaming\\python\\python311\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.48b0)\n",
      "Requirement already satisfied: setuptools>=16.0 in c:\\users\\rsc\\.conda\\envs\\dsml33_env1\\lib\\site-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (72.1.0)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in c:\\users\\rsc\\.conda\\envs\\dsml33_env1\\lib\\site-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: asgiref~=3.0 in c:\\users\\rsc\\appdata\\roaming\\python\\python311\\site-packages (from opentelemetry-instrumentation-asgi==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in c:\\users\\rsc\\appdata\\roaming\\python\\python311\\site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\rsc\\appdata\\roaming\\python\\python311\\site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\rsc\\appdata\\roaming\\python\\python311\\site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\rsc\\appdata\\roaming\\python\\python311\\site-packages (from pydantic>=1.9->chromadb) (2.23.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\rsc\\.conda\\envs\\dsml33_env1\\lib\\site-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\rsc\\.conda\\envs\\dsml33_env1\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.15.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\rsc\\appdata\\roaming\\python\\python311\\site-packages (from tokenizers>=0.13.2->chromadb) (0.25.1)\n",
      "Collecting click>=8.0.0 (from typer>=0.9.0->chromadb)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\rsc\\appdata\\roaming\\python\\python311\\site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.5.0 in c:\\users\\rsc\\appdata\\roaming\\python\\python311\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.2)\n",
      "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\rsc\\appdata\\roaming\\python\\python311\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.24.0)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\users\\rsc\\appdata\\roaming\\python\\python311\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (13.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\rsc\\appdata\\roaming\\python\\python311\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.0)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\rsc\\appdata\\roaming\\python\\python311\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Collecting filelock (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb)\n",
      "  Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\rsc\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.9.0)\n",
      "Collecting zipp>=0.5 (from importlib-metadata<=8.4.0,>=6.0->opentelemetry-api>=1.2.0->chromadb)\n",
      "  Downloading zipp-3.20.2-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\rsc\\.conda\\envs\\dsml33_env1\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rsc\\.conda\\envs\\dsml33_env1\\lib\\site-packages (from requests->kubernetes>=28.1.0->chromadb) (3.3.2)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\rsc\\appdata\\roaming\\python\\python311\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\rsc\\appdata\\roaming\\python\\python311\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb) (3.5.4)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Downloading tokenizers-0.20.1-cp311-none-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.4 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 0.8/2.4 MB 2.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.6/2.4 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.4/2.4 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 3.0 MB/s eta 0:00:00\n",
      "Downloading tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Downloading importlib_metadata-8.4.0-py3-none-any.whl (26 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "Downloading sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 1.6/6.2 MB 9.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 3.7/6.2 MB 9.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 6.0/6.2 MB 10.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.2/6.2 MB 9.3 MB/s eta 0:00:00\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 536.2/536.2 kB 5.8 MB/s eta 0:00:00\n",
      "Downloading pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "Downloading zipp-3.20.2-py3-none-any.whl (9.2 kB)\n",
      "Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Installing collected packages: mpmath, zipp, websocket-client, tqdm, sympy, python-dotenv, pyasn1, overrides, filelock, click, pyasn1-modules, importlib-metadata, tokenizers\n",
      "Successfully installed click-8.1.7 filelock-3.16.1 importlib-metadata-8.4.0 mpmath-1.3.0 overrides-7.7.0 pyasn1-0.6.1 pyasn1-modules-0.4.1 python-dotenv-1.0.1 sympy-1.13.3 tokenizers-0.20.1 tqdm-4.66.5 websocket-client-1.8.0 zipp-3.20.2\n"
     ]
    }
   ],
   "source": [
    "pip install chromadb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9cf5fcf-393a-46bc-b3c4-b7bbaa6c9201",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "chroma_client = chromadb.Client()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aead24db-4a90-43dc-bea4-944c7a7019c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = chroma_client.create_collection(name=\"my_collection\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb025729-e9e9-4b7f-a6be-e6ecc711b9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add(\n",
    "    documents=[\n",
    "        \"John, a Computer Science graduate, skilled in Python, machine learning, and data preprocessing. Completed customer churn prediction project. Enthusiastic learner.\",\n",
    "        \"Emily, a Statistics graduate, proficient in R, data visualization, and hypothesis testing. Completed climate data visualization project. Analytical and detail-oriented.\",\n",
    "        \"Rahul, an IT graduate, with expertise in Python, SQL, and data visualization. Developed an e-commerce recommendation system. Eager learner.\",\n",
    "        \"Sophia, a Mathematics graduate, skilled in machine learning, NLP, and Python. Completed a sentiment analysis project. Passionate about AI.\"\n",
    "    ],\n",
    "    ids=[\"John\", \"Emily\",\"Rahul\",\"Sophia\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b509f65-b77e-4ab7-87b3-10c10b2c64fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': [['Rahul', 'John']], 'embeddings': None, 'documents': [['Rahul, an IT graduate, with expertise in Python, SQL, and data visualization. Developed an e-commerce recommendation system. Eager learner.', 'John, a Computer Science graduate, skilled in Python, machine learning, and data preprocessing. Completed customer churn prediction project. Enthusiastic learner.']], 'uris': None, 'data': None, 'metadatas': [[None, None]], 'distances': [[1.2399588823318481, 1.3001580238342285]], 'included': [<IncludeEnum.distances: 'distances'>, <IncludeEnum.documents: 'documents'>, <IncludeEnum.metadatas: 'metadatas'>]}\n"
     ]
    }
   ],
   "source": [
    "results = collection.query(\n",
    "    query_texts=[\"we are in need of python devloper with at least 2 years of experience\"], # Chroma will embed this for you\n",
    "    n_results=2 # how many results to return\n",
    ")\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5825c176-4162-4979-8ca4-1fd8521c8bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_post='''Way of working - Remote: Employees will have the freedom to work remotely all through the year. These employees, who form a large majority, will come together in their base location for a week, once every quarter.\n",
    "Data Science at SwiggyData Science and applied ML is ingrained deeply in decision making and product development at Swiggy. Our data scientists work closely with cross-functional teams to ship end-to-end data products, from formulating the business problem in mathematical/ML terms to iterating on ML/DL methods to taking them to production. We own or co-own several initiatives with a direct line of sight to impact on customer experience as well as business metrics. We also encourage open sharing of ideas and publishing in internal and external avenues.\n",
    "About the Ads Monetization TeamThis team is responsible for building and optimizing ML solutions for the full lifecycle of ads across both Food and Instamart Business lines, everything from sourcing the right set of ads to pricing them to targeting them via personalized and multi-objective-optimized user-response models. Ads being one of the highest throughput and lowest latency systems at Swiggy, we are also maniacally focused about delivering pragmatic and scalable solutions. \n",
    "What you will doYou will leverage your strong ML/DL/Statistics background to build new and next generation of ML based solutions to improve the quality of ads recommendation and leverage various optimization techniques to improve the campaign performance.You will mine and extract relevant information from Swiggy's massive historical data to help ideate and identify solutions to business and CX problems.You will work closely with engineers/PMs/analysts on detailed requirements, technical designs, and implementation of end-to-end inference solutions at Swiggy scale.You will stay abreast with the latest in ML research for Ads Bidding algorithms, Recommendation Systems related areas and help adapt it to Swiggy's problem statements.You will publish and talk about your work in internal and external forums to both technical and layman audiences.\n",
    "QualificationsBachelors or Masters degree in a quantitative field with 0-2 years of industry/research lab experienceRequired: Excellent problem solving skills, ability to deconstruct and formulate solutions from first-principlesRequired: Depth and hands-on experience in applying ML/DL, statistical techniques to business problemsPreferred: Experience working with ‘big data’ and shipping ML/DL models to productionRequired: Strong proficiency in Python, SQL, Spark, TensorflowRequired: Strong spoken and written communication skillsBig plus: Experience in the space of ecommerce and logistics'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2327fc69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```\n",
      "{\n",
      "  \"JOB_ROLE\": \"Data Scientist - Ads Monetization\",\n",
      "  \"EXPERIENCE\": \"0-2 years\",\n",
      "  \"SKILLS\": [\n",
      "    \"ML/DL\",\n",
      "    \"Statistics\",\n",
      "    \"Python\",\n",
      "    \"SQL\",\n",
      "    \"Spark\",\n",
      "    \"Tensorflow\",\n",
      "    \"Problem-solving\",\n",
      "    \"Communication\"\n",
      "  ]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You have to extract following details from provided job post.Extract JOB_ROLE,EXPERINCE,SKILLS in json format.don't provide preamble information\"\n",
    "        ),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "results=chain.invoke(\n",
    "    {\n",
    "        \"input\":job_post,\n",
    "    }\n",
    ")\n",
    "print(results.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09e3ffc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da26923e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'JOB_ROLE': 'Data Scientist - Ads Monetization',\n",
       " 'EXPERIENCE': '0-2 years',\n",
       " 'SKILLS': ['ML/DL',\n",
       "  'Statistics',\n",
       "  'Python',\n",
       "  'SQL',\n",
       "  'Spark',\n",
       "  'Tensorflow',\n",
       "  'Problem-solving',\n",
       "  'Communication']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "details=json.loads(results.content.strip(\"`\\n\"))\n",
    "details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2793865c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ML/DL Statistics Python SQL Spark Tensorflow Problem-solving Communication'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skills=' '.join(details['SKILLS'])\n",
    "skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "723d1b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': [['John', 'Sophia']], 'embeddings': None, 'documents': [['John, a Computer Science graduate, skilled in Python, machine learning, and data preprocessing. Completed customer churn prediction project. Enthusiastic learner.', 'Sophia, a Mathematics graduate, skilled in machine learning, NLP, and Python. Completed a sentiment analysis project. Passionate about AI.']], 'uris': None, 'data': None, 'metadatas': [[None, None]], 'distances': [[1.4242303371429443, 1.429412841796875]], 'included': [<IncludeEnum.distances: 'distances'>, <IncludeEnum.documents: 'documents'>, <IncludeEnum.metadatas: 'metadatas'>]}\n"
     ]
    }
   ],
   "source": [
    "results = collection.query(\n",
    "    query_texts=[skills], # Chroma will embed this for you\n",
    "    n_results=2 # how many results to return\n",
    ")\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5756147a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'John, a Computer Science graduate, skilled in Python, machine learning, and data preprocessing. Completed customer churn prediction project. Enthusiastic learner. Sophia, a Mathematics graduate, skilled in machine learning, NLP, and Python. Completed a sentiment analysis project. Passionate about AI.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolio=' '.join(results['documents'][0])\n",
    "portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8fceb03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Suitable Candidates for TCS Job Role\n",
      "\n",
      "Dear Recruitment Team,\n",
      "\n",
      "We are pleased to submit the portfolios of two exceptional candidates who we believe are well-suited for the job role at TCS. Below are the details of the shortlisted candidates:\n",
      "\n",
      "1. Candidate 1: John\n",
      "- Qualification: Computer Science graduate\n",
      "- Key Skills: Python, Machine Learning, Data Preprocessing\n",
      "- Notable Project: Customer Churn Prediction\n",
      "- Strengths: Enthusiastic learner, strong technical skills\n",
      "\n",
      "2. Candidate 2: Sophia\n",
      "- Qualification: Mathematics graduate\n",
      "- Key Skills: Machine Learning, NLP, Python\n",
      "- Notable Project: Sentiment Analysis\n",
      "- Strengths: Passionate about AI, strong analytical skills\n",
      "\n",
      "Both candidates have demonstrated a strong foundation in their respective fields and have hands-on experience with relevant projects. We believe they would be valuable additions to the TCS team.\n",
      "\n",
      "We would be happy to schedule interviews for these candidates at your earliest convenience. Please let us know if you require any additional information or would like to proceed with the next steps.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "[Your Name]\n",
      "Placement Officer\n",
      "[Your Consultancy Name]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Email_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            '''we are working as a placement officer in placement consultancy. we have shortlisted candidates portfolio of TCS job post.Create an Email to recrutment team of tcs mentioning that we have best suitable candidate for your job role. do  not provide any preamle''',\n",
    "        ),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "Email_chain = Email_prompt | llm\n",
    "results=Email_chain.invoke(\n",
    "    {\n",
    "        \"input\":portfolio,\n",
    "    }\n",
    ")\n",
    "print(results.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d808dbce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
